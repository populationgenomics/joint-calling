{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.init(default_reference='GRCh38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import bokeh\n",
    "from bokeh.layouts import gridplot, row, widgetbox\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook, push_notebook, export_png\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.palettes import *\n",
    "from bokeh.models import *\n",
    "from typing import *\n",
    "from bokeh.plotting.helpers import stack\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "from gnomad.variant_qc.evaluation import add_rank\n",
    "from joint_calling import utils\n",
    "\n",
    "overwrite = True\n",
    "work_bucket = 'gs://cpg-tob-wgs-test-analysis/jupyter/vsavelyev'\n",
    "TRUTH_SAMPLE = 'NA12878'\n",
    "\n",
    "from bokeh.io import show, output_notebook, reset_output\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "\n",
    "gvcf_by_key = {\n",
    "    'from_broad_gvcf': 'gs://cpg-thousand-genomes-test/gvcf/NA12878-from-broad-gvcf.g.vcf.gz',\n",
    "    'from_cram'      : 'gs://cpg-thousand-genomes-test/gvcf/NA12878-from-cram.g.vcf.gz',\n",
    "    'realign'        : 'gs://cpg-thousand-genomes-test/gvcf/NA12878-realign.g.vcf.gz',\n",
    "    'hc_realign'     : 'gs://cpg-thousand-genomes-test/gvcf/NA12878-hc-from-bam.g.vcf.gz',\n",
    "#     'hc_realign'     : 'gs://cpg-thousand-genomes-test/gvcf/NA12878-hc-realign.g.vcf.gz',\n",
    "}\n",
    "\n",
    "# fewgenomes_v2_mt_path = 'gs://cpg-fewgenomes-main/mt/v2-nonref.mt'\n",
    "# fewgenomes_v2_raw_mt_path = 'gs://cpg-fewgenomes-main-tmp/joint-calling/v2/combiner/v2-raw.mt'\n",
    "# meta_v2_ht_path = 'gs://cpg-fewgenomes-main-metadata/joint-calling/v2/meta.ht'\n",
    "# vqsr_final_filter_ht_path = 'gs://cpg-fewgenomes-main-tmp/joint-calling/v2/variant_qc/vqsr/final-filter.ht'\n",
    "highconf_ht_path = 'gs://cpg-reference/validation/giab/regions/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_nosomaticdel_noCENorHET7_hc_regions.ht/'\n",
    "\n",
    "def filter_highconf(mt):\n",
    "    highconf_bed_ht = hl.read_table(highconf_ht_path)\n",
    "    mt = mt.filter_rows(hl.is_defined(highconf_bed_ht[mt.locus]))\n",
    "    return mt\n",
    "\n",
    "def print_conc_summary(summary):\n",
    "    print('Summary:')\n",
    "    print(summary)\n",
    "    tp = summary[2][2] + summary[3][3] + summary[4][4]\n",
    "    total_discordant = sum([sum(s[2:]) for s in summary[2:]]) - tp\n",
    "    called = sum([sum(s[:]) for s in summary[2:]])\n",
    "    truth = sum([sum(s[2:]) for s in summary[:]])\n",
    "    fp = called - tp\n",
    "    fn = truth - tp\n",
    "    precision = tp / called\n",
    "    recall = tp / truth\n",
    "    print(f'Left = called: {called}')\n",
    "    print(f'Right = truth: {truth}')\n",
    "    print(f'Unique to left = FP [precision]: {fp} [{precision:.2%}]')\n",
    "    print(f'Unique to right = FN [recall]: {fn} [{recall:.2%}]')\n",
    "    print(f'Concordant = TP [discordant]: {tp} [{total_discordant}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excellent-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13986427, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realign_mt_path = join(work_bucket, 'from_gvcfs', f'hc_realign.mt')\n",
    "mt = hl.read_matrix_table(realign_mt_path)\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjacent-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------------+-------------------+\n",
       "| locus         | alleles           |\n",
       "+---------------+-------------------+\n",
       "| locus<GRCh38> | array<str>        |\n",
       "+---------------+-------------------+\n",
       "| chr1:1        | [\"N\",\"<NON_REF>\"] |\n",
       "| chr1:10013    | [\"T\",\"<NON_REF>\"] |\n",
       "| chr1:10114    | [\"T\",\"<NON_REF>\"] |\n",
       "| chr1:10116    | [\"A\",\"<NON_REF>\"] |\n",
       "| chr1:10120    | [\"T\",\"<NON_REF>\"] |\n",
       "| chr1:10121    | [\"A\",\"<NON_REF>\"] |\n",
       "| chr1:10126    | [\"T\",\"<NON_REF>\"] |\n",
       "| chr1:10127    | [\"A\",\"<NON_REF>\"] |\n",
       "| chr1:10132    | [\"T\",\"<NON_REF>\"] |\n",
       "| chr1:10133    | [\"A\",\"<NON_REF>\"] |\n",
       "+---------------+-------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "realign_mt_path = join(work_bucket, 'from_gvcfs', f'realign.mt')\n",
    "mt = hl.read_matrix_table(realign_mt_path)\n",
    "mt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "olympic-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_broad_gvcf\n",
      "(20370777, 1)\n",
      "from_cram\n",
      "(20358543, 1)\n",
      "realign\n",
      "(19653459, 1)\n",
      "hc_realign\n",
      "(13986427, 1)\n"
     ]
    }
   ],
   "source": [
    "mt_by_key = dict()\n",
    "for k, gvcf_path in gvcf_by_key.items():\n",
    "    mt_path = join(work_bucket, 'from_gvcfs', f'{k}.mt')\n",
    "    if not utils.file_exists(mt_path):\n",
    "        mt = hl.import_vcf(gvcf_path, force_bgz=True) \n",
    "        mt.write(mt_path, overwrite=True)\n",
    "    mt = hl.read_matrix_table(mt_path)\n",
    "    mt_by_key[k] = mt\n",
    "    print(k)\n",
    "    print(mt.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "underlying-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_broad_gvcf': <hail.matrixtable.MatrixTable at 0x7ff7f65bdf10>,\n",
       " 'from_cram': <hail.matrixtable.MatrixTable at 0x7ff7f660e490>,\n",
       " 'realign': <hail.matrixtable.MatrixTable at 0x7ff7f65ef8b0>,\n",
       " 'hc_realign': <hail.matrixtable.MatrixTable at 0x7ff7f66f5af0>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_by_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-booking",
   "metadata": {},
   "source": [
    "# Compare downloaded with recalled gvcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_by_key = {\n",
    "    k: hl.split_multi(mt)\n",
    "    for k, mt in mt_by_key.items()\n",
    "}\n",
    "\n",
    "mt_by_key = {\n",
    "    k: filter_highconf(mt) \n",
    "    for k, mt in mt_by_key.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "searching-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_broad_gvcf': (14668414, 1),\n",
       " 'from_cram': (14668278, 1),\n",
       " 'realign': (14425591, 1),\n",
       " 'hc_realign': (0, 1)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: mt.count() for k, mt in mt_by_key.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "modular-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_mt_path = (\n",
    "    'gs://cpg-reference/validation/giab/truth/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.mt/'\n",
    ")\n",
    "truth_mt = hl.read_matrix_table(truth_mt_path)\n",
    "truth_mt = truth_mt.key_cols_by(s = truth_mt.s.replace('HG001', TRUTH_SAMPLE))\n",
    "truth_mt = filter_highconf(truth_mt)\n",
    "truth_mt = hl.split_multi(truth_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cordless-partner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">s</div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">str</td></tr>\n",
       "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;NA12878&quot;</td></tr>\n",
       "</tbody></table>"
      ],
      "text/plain": [
       "+-----------+\n",
       "| s         |\n",
       "+-----------+\n",
       "| str       |\n",
       "+-----------+\n",
       "| \"NA12878\" |\n",
       "+-----------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truth_mt.cols().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'from_broad_gvcf': (14668414, 1),\n",
       "  'from_cram': (14668278, 1),\n",
       "  'realign': (14425591, 1),\n",
       "  'hc_realign': (0, 1)},\n",
       " (3577097, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: mt.count() for k, mt in mt_by_key.items()}, truth_mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.filter_intervals(truth_mt, [hl.parse_locus_interval('chr5:1917500-1917600')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "human-shade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 05:35:31 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-09-23 05:35:31 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 9761, 7472], [230, 0, 0, 20, 2], [7439147, 0, 0, 0, 0], [2249523, 0, 0, 2128827, 5846], [1419650, 0, 0, 886, 1424283]]\n",
      "Left = called: 14668162\n",
      "Right = truth: 3577097\n",
      "Unique to left = FP [precision]: 11115052 [24.22%]\n",
      "Unique to right = FN [recall]: 23987 [99.33%]\n",
      "Concordant = TP [discordant]: 3553110 [6732]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:01:07 Hail: INFO: concordance: total concordance 99.81%\n"
     ]
    }
   ],
   "source": [
    "summary, sample_conc_ht, sites_conc_ht = hl.concordance(mt_by_key['from_broad_gvcf'], truth_mt)\n",
    "print_conc_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indoor-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:01:09 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-09-23 06:01:09 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 9760, 7473], [5, 0, 0, 0, 1], [7439117, 0, 0, 0, 0], [2249625, 0, 0, 2128847, 5826], [1419667, 0, 0, 887, 1424303]]\n",
      "Left = called: 14668272\n",
      "Right = truth: 3577097\n",
      "Unique to left = FP [precision]: 11115122 [24.22%]\n",
      "Unique to right = FN [recall]: 23947 [99.33%]\n",
      "Concordant = TP [discordant]: 3553150 [6713]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:06:57 Hail: INFO: concordance: total concordance 99.81%\n"
     ]
    }
   ],
   "source": [
    "summary_from_cram, sample_conc_from_cram_ht, sites_conc_from_cram_ht = hl.concordance(mt_by_key['from_cram'], truth_mt)\n",
    "print_conc_summary(summary_from_cram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "removed-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">s</div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">str</td></tr>\n",
       "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;NA12878-hc-from-bam&quot;</td></tr>\n",
       "</tbody></table>"
      ],
      "text/plain": [
       "+-----------------------+\n",
       "| s                     |\n",
       "+-----------------------+\n",
       "| str                   |\n",
       "+-----------------------+\n",
       "| \"NA12878-hc-from-bam\" |\n",
       "+-----------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NA12878-realign'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_by_key['hc_realign'].cols().show()\n",
    "'NA12878-realign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nervous-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 11:30:28 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-09-23 11:30:28 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 47400, 30632], [5, 0, 0, 0, 1], [7340257, 0, 0, 0, 0], [2188999, 0, 0, 2090667, 5656], [1397265, 0, 0, 1427, 1401314]]\n",
      "Left = called: 14425585\n",
      "Right = truth: 3577097\n",
      "Unique to left = FP [precision]: 10933604 [24.21%]\n",
      "Unique to right = FN [recall]: 85116 [97.62%]\n",
      "Concordant = TP [discordant]: 3491981 [7083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 11:38:53 Hail: INFO: concordance: total concordance 99.80%\n"
     ]
    }
   ],
   "source": [
    "mt_by_key['realign'] = mt_by_key['realign'].key_cols_by(s = mt_by_key['realign'].s.replace('NA12878-realign', TRUTH_SAMPLE))\n",
    "summary_realign, sample_conc_realign_ht, sites_conc_realign_ht = hl.concordance(mt_by_key['realign'], truth_mt)\n",
    "print_conc_summary(summary_realign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unlikely-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 11:38:55 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-09-23 11:38:55 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 42762, 25937], [4, 0, 0, 0, 0], [4768219, 0, 0, 0, 0], [2161416, 0, 0, 2095253, 2043], [1392993, 0, 0, 1479, 1409623]]\n",
      "Left = called: 11831026\n",
      "Right = truth: 3577097\n",
      "Unique to left = FP [precision]: 8326150 [29.62%]\n",
      "Unique to right = FN [recall]: 72221 [97.98%]\n",
      "Concordant = TP [discordant]: 3504876 [3522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 11:41:30 Hail: INFO: concordance: total concordance 99.90%\n"
     ]
    }
   ],
   "source": [
    "mt_by_key['hc_realign'] = mt_by_key['hc_realign'].key_cols_by(s = mt_by_key['hc_realign'].s.replace(mt_by_key['hc_realign'].s.collect()[0], TRUTH_SAMPLE))\n",
    "summary_realign_hc, sample_conc_realign_hc_ht, sites_conc_realign_hc_ht = hl.concordance(mt_by_key['hc_realign'], truth_mt)\n",
    "print_conc_summary(summary_realign_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addressed-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conc(key):\n",
    "    mt = mt_by_key[key]\n",
    "    print(f'{key}: running concordance')\n",
    "    summary, sample_conc_ht, sites_conc_ht = hl.concordance(mt, truth_mt)\n",
    "    print_conc_summary(summary)\n",
    "    print(f'{key}: writing summary')\n",
    "    with hl.hadoop_open(f'{work_bucket}/results/summary_{key}.pickle', 'w') as f:\n",
    "        f.write(str(summary))\n",
    "    print(f'{key}: writing sample_conc_ht')\n",
    "    sample_conc_ht = sample_conc_ht.checkpoint(f'{work_bucket}/results/sample_conc_{key}.ht')\n",
    "    print(f'{key}: writing sites_conc_ht')\n",
    "    sites_conc_ht = sites_conc_ht.checkpoint(f'{work_bucket}/results/sites_conc_{key}.ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "finite-matter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_broad_gvcf: running concordance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 04:54:30 Hail: INFO: concordance: including 0 shared samples (1 total on left, 1 total on right)\n",
      "2021-09-23 04:54:30 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 04:56:56 Hail: INFO: concordance: total concordance nan%\n"
     ]
    }
   ],
   "source": [
    "for k in mt_by_key:\n",
    "    run_conc(k)\n",
    "    \n",
    "gnomad_mt = gnomad_mt.key_cols_by(s = gnomad_mt.s.replace('gnomad_sn', 'NA12878'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "molecular-sector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cpg-tob-wgs-test-analysis/jupyter/vsavelyev/results\n"
     ]
    }
   ],
   "source": [
    "print(f'{work_bucket}/results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-issue",
   "metadata": {},
   "source": [
    "# From fewgenomes joint-calling MT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-variable",
   "metadata": {},
   "source": [
    "### Reading the fewgenomes matrix table of 122 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quick-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = utils.get_mt(\n",
    "    fewgenomes_v2_raw_mt_path, \n",
    "    split=True, \n",
    "    add_meta=True, \n",
    "    meta_ht=hl.read_table(meta_v2_ht_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-minute",
   "metadata": {},
   "source": [
    "### Subsetting to NA12878 - 5m variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sharing-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5139649, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt = mt.filter_cols(hl.literal([TRUTH_SAMPLE]).contains(mt['s']))\n",
    "mt = mt.filter_rows((hl.len(mt.alleles) > 1) & (hl.agg.any(mt.GT.is_non_ref())))\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-james",
   "metadata": {},
   "source": [
    "### Annotating with VQSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "every-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqsr_ht = hl.read_table(vqsr_final_filter_ht_path)\n",
    "mt = mt.annotate_rows(**vqsr_ht[mt.row_key])\n",
    "mt = mt.annotate_globals(**vqsr_ht.index_globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-venice",
   "metadata": {},
   "source": [
    "### Subsetting to passing variants (5.1m down to 4.3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "seeing-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599509421752342"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtf = mt.filter_rows(mt.filters.length() == 0)\n",
    "mtf.rows().count() / mt.rows().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "gorgeous-appliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4419846, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtf.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-bolivia",
   "metadata": {},
   "source": [
    "### Subsetting to chr21 for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "radio-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt21 = hl.filter_intervals(mt, [hl.parse_locus_interval('chr21')])\n",
    "mt21f = mt21.filter_rows(mt21.filters.length() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "funky-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90102, 1), (62536, 1), 0.6940578455528179)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt21.rows().count(), mt21f.rows().count(), mt21f.rows().count() / mt21.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-orchestra",
   "metadata": {},
   "source": [
    "### Subsetting to the NA12878 high confidence regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_hc = filter_highconf(mt)\n",
    "mtf_hc = filter_highconf(mtf)\n",
    "mt21_hc = filter_highconf(mt21)\n",
    "mt21f_hc = filter_highconf(mt21f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-tooth",
   "metadata": {},
   "source": [
    "### Saving to the disk to faster reruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cooperative-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_path = join(work_bucket, 'mt.mt')\n",
    "mtf_path = join(work_bucket, 'mtf.mt')\n",
    "mt21_path = join(work_bucket, 'mt21.mt')\n",
    "mt21f_path = join(work_bucket, 'mt21f.mt')\n",
    "mt_hc_path = join(work_bucket, 'mt_hc.mt')\n",
    "mtf_hc_path = join(work_bucket, 'mtf_hc.mt')\n",
    "mt21_hc_path = join(work_bucket, 'mt21_hc.mt')\n",
    "mt21f_hc_path = join(work_bucket, 'mt21f_hc.mt')\n",
    "# mt.write(mt_path, overwrite=True)\n",
    "# mtf.write(mtf_path, overwrite=True)\n",
    "# mt21.write(mt21_path, overwrite=True)\n",
    "# mt21f.write(mt21f_path, overwrite=True)\n",
    "# mt_hc.write(mt_hc_path, overwrite=True)\n",
    "# mtf_hc.write(mtf_hc_path, overwrite=True)\n",
    "# mt21_hc.write(mt21_hc_path, overwrite=True)\n",
    "# mt21f_hc.write(mt21f_hc_path, overwrite=True)\n",
    "mt = hl.read_matrix_table(mt_path)\n",
    "mtf = hl.read_matrix_table(mtf_path)\n",
    "mt21 = hl.read_matrix_table(mt21_path)\n",
    "mt21f = hl.read_matrix_table(mt21f_path)\n",
    "mt_hc = hl.read_matrix_table(mt_hc_path)\n",
    "mtf_hc = hl.read_matrix_table(mtf_hc_path)\n",
    "mt21_hc = hl.read_matrix_table(mt21_hc_path)\n",
    "mt21f_hc = hl.read_matrix_table(mt21f_hc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-emerald",
   "metadata": {},
   "source": [
    "### Exploring % of filtered and % of HC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-theory",
   "metadata": {},
   "source": [
    "There are ~30% of variants outside of the HC regions (5.1m > 3.6m), \n",
    "or ~22% (4.3m > 3.3m) for filtered variants only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "danish-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7008891074079183, 0.7859941273971989)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_hc.rows().count() / mt.rows().count(), \\\n",
    "mtf_hc.rows().count() / mtf.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-benefit",
   "metadata": {},
   "source": [
    "Percentages are a bit difference for chr21:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "miniature-niger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5759694568378061, 0.8136913138032493)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt21_hc.rows().count() / mt21.rows().count(), mt21f_hc.rows().count() / mt21f.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-uruguay",
   "metadata": {},
   "source": [
    "Plotting the filtered variants % per contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cooked-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = hl.get_reference('GRCh38')\n",
    "contigs = [c for c in ref.contigs if len(c) <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "anonymous-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_contig = [hl.filter_intervals(mt_hc, [hl.parse_locus_interval(c)]).rows().count() for c in contigs]\n",
    "filtered_per_contig = [hl.filter_intervals(mtf_hc, [hl.parse_locus_interval(c)]).rows().count() for c in contigs]\n",
    "gn_total_per_contig = [hl.filter_intervals(gnomad_hc_mt, [hl.parse_locus_interval(c)]).rows().count() for c in contigs]\n",
    "gn_filtered_per_contig = [hl.filter_intervals(gnomad_hc_mtf, [hl.parse_locus_interval(c)]).rows().count() for c in contigs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(x_range=contigs)\n",
    "p.vbar(x=contigs, top=[\n",
    "    (float(f) / float(t) * total_per_contig[0]) if t else 0 \n",
    "    for t, f in zip(total_per_contig, filtered_per_contig)], \n",
    "       width=1, color='black', fill_color='white')\n",
    "p.vbar(x=contigs, top=total_per_contig, width=1, color='blue')\n",
    "p.vbar(x=contigs, top=filtered_per_contig, width=1, color='red')\n",
    "reset_output()\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(x_range=contigs)\n",
    "p.vbar(x=contigs, top=[\n",
    "    (float(f) / float(t) * gn_total_per_contig[0]) if t else 0 \n",
    "    for t, f in zip(gn_total_per_contig, gn_filtered_per_contig)], \n",
    "       width=1, color='black', fill_color='white')\n",
    "p.vbar(x=contigs, top=gn_total_per_contig, width=1, color='blue')\n",
    "p.vbar(x=contigs, top=gn_filtered_per_contig, width=1, color='red')\n",
    "reset_output()\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-amazon",
   "metadata": {},
   "source": [
    "### Exploring AS_VQSLOD\n",
    "AS_VQSLOD goes into very negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_output()\n",
    "output_notebook()\n",
    "show(hl.plot.histogram(mt21.aggregate_entries(hl.expr.aggregators.hist(mt21.AS_VQSLOD, -80, 20, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "medium-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33583.5947"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt21.aggregate_rows(hl.agg.min(mt21.AS_VQSLOD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-benchmark",
   "metadata": {},
   "source": [
    "Now after removing the filtered variants. It's evident that filtering is performed on a certain threshold of the score derived from AS_VQSLOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alien-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"1c100d98-a904-4010-b9ed-a166462035f0\" data-root-id=\"1133\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(hl.plot.histogram(mt21f.aggregate_entries(hl.expr.aggregators.hist(mt21f.AS_VQSLOD, -80, 20, 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-carolina",
   "metadata": {},
   "source": [
    "### Preprare the truth sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "external-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3659369, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_mt_path = (\n",
    "    'gs://gnomad-public/resources/grch38/na12878/'\n",
    "    'HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1'\n",
    "    '-X_v.3.3.2_highconf_PGandRTGphasetransfer.mt'\n",
    ")\n",
    "truth_mt = hl.read_matrix_table(truth_mt_path)\n",
    "# truth_mt = truth_mt.key_cols_by(s=hl.str(TRUTH_SAMPLE))\n",
    "# truth_mt = hl.split_multi_hts(truth_mt, left_aligned=False)\n",
    "# truth_mt = truth_mt.filter_rows(hl.agg.any(truth_mt.GT.is_non_ref()))\n",
    "truth_mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separated-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_mt21 = hl.filter_intervals(truth_mt, [hl.parse_locus_interval('chr21')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-composite",
   "metadata": {},
   "source": [
    "The truth sample variants sitting almost entirely in the HC regions, however 2.5% are outside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_mt_hc = filter_highconf(truth_mt)\n",
    "truth_mt_hc.rows().count() / truth_mt.rows().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-teddy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "truth_mt21_hc = filter_highconf(truth_mt21)\n",
    "truth_mt21_hc.rows().count() / truth_mt21.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-reception",
   "metadata": {},
   "source": [
    "Saving on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_mt_path = join(work_bucket, 'truth_mt_hc.mt')\n",
    "truth_mt21_path = join(work_bucket, 'truth_mt21_hc.mt')\n",
    "# truth_mt.write(truth_mt_path)\n",
    "# truth_mt21.write(truth_mt21_path)\n",
    "truth_mt = hl.read_matrix_table(truth_mt_path)\n",
    "truth_mt21 = hl.read_matrix_table(truth_mt21_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-awareness",
   "metadata": {},
   "source": [
    "### Evaluation: concordance with truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-unknown",
   "metadata": {},
   "source": [
    "Our matrix table against the truth showed the concodrance of 99.98%, with a bit higher 2% FN rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "industrial-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 15:04:44 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-26 15:04:44 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 865, 533], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [194, 0, 0, 31564, 5], [33, 0, 0, 6, 20094]]\n",
      "Left = called: 51896\n",
      "Right = truth: 53067\n",
      "Unique to left = FP [precision]: 238 [99.54%]\n",
      "Unique to right = FN [recall]: 1409 [97.34%]\n",
      "Concordant = TP [discordant]: 51658 [11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 15:05:06 Hail: INFO: concordance: total concordance 99.98%\n",
      "2021-07-26 15:05:06 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n"
     ]
    }
   ],
   "source": [
    "summary21, sample_conc_21ht, sites_conc_21ht = hl.concordance(mt21, truth_mt21)\n",
    "print_conc_summary(summary21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_vs_truthmt_summary, sample_concordance_ht, sites_concordance_ht = hl.concordance(mt, truth_mt)\n",
    "print_conc_summary(mt_vs_truthmt_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-export",
   "metadata": {},
   "source": [
    "### Evaluation: concordnace after filtering to PASS variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-leather",
   "metadata": {},
   "source": [
    "Higher precision, but even lower recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "threatened-discipline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:35:55 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-26 11:35:55 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 1386, 837], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [16, 0, 0, 31044, 5], [25, 0, 0, 5, 19790]]\n",
      "Left = called: 50885\n",
      "Right = truth: 53067\n",
      "Unique to left = FP [precision]: 51 [99.90%]\n",
      "Unique to right = FN [recall]: 2233 [95.79%]\n",
      "Concordant = TP [discordant]: 50834 [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:36:00 Hail: INFO: concordance: total concordance 99.98%\n"
     ]
    }
   ],
   "source": [
    "summary21f, _, _ = hl.concordance(mt21f_hc, truth_mt21)\n",
    "print_conc_summary(summary21f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_vs_truthmt_summaryf, _, _ = hl.concordance(mtf_hc, truth_mt)\n",
    "print_conc_summary(mt_vs_truthmt_summaryf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-colon",
   "metadata": {},
   "source": [
    "### Compare with gnomad mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-victory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnomad_mt_path = 'gs://gcp-public-data--gnomad/release/3.1/mt/genomes/gnomad.genomes.v3.1.hgdp_1kg_subset_dense.mt/'\n",
    "gnomad_mt = hl.read_matrix_table(gnomad_mt_path)\n",
    "gnomad_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_sn = 'v3.1::NA12878'\n",
    "gnomad_mt = gnomad_mt.key_cols_by(s = gnomad_mt.s.replace(gnomad_sn, TRUTH_SAMPLE))\n",
    "gnomad_mt = gnomad_mt.filter_cols(hl.literal([TRUTH_SAMPLE]).contains(gnomad_mt['s']))\n",
    "gnomad_mt = gnomad_mt.filter_rows((hl.len(gnomad_mt.alleles) > 1) & (hl.agg.any(gnomad_mt.GT.is_non_ref())))\n",
    "gnomad_mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-negative",
   "metadata": {},
   "source": [
    "Subset to PASSing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assumed-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_mtf = gnomad_mt.filter_rows(gnomad_mt.filters.length() == 0)\n",
    "gnomad_mt21 = hl.filter_intervals(gnomad_mt, [hl.parse_locus_interval('chr21')])\n",
    "gnomad_mt21f = gnomad_mt21.filter_rows(gnomad_mt21.filters.length() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-translator",
   "metadata": {},
   "source": [
    "Are there multiallelics? - no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnomad_mt.filter_rows(hl.len(gnomad_mt.alleles) > 2).rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-plate",
   "metadata": {},
   "source": [
    "### Subset to highconf regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "featured-discovery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_hc_mt = filter_highconf(gnomad_mt)\n",
    "gnomad_hc_mtf =  gnomad_hc_mt.filter_rows(gnomad_hc_mt.filters.length() == 0)\n",
    "gnomad_hc_mt21 = hl.filter_intervals(gnomad_hc_mt, [hl.parse_locus_interval('chr21')])\n",
    "gnomad_hc_mt21f = gnomad_mt21_hc.filter_rows(gnomad_hc_mt21.filters.length() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-spine",
   "metadata": {},
   "source": [
    "Saving on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advisory-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_mt_path = join(work_bucket, 'gnomad.mt')\n",
    "gnomad_mtf_path = join(work_bucket, 'gnomad.filt.mt')\n",
    "gnomad_mt21_path = join(work_bucket, 'gnomad.chr21.mt')\n",
    "gnomad_mt21f_path = join(work_bucket, 'gnomad.chr21.filt.mt')\n",
    "gnomad_hc_mt_path = join(work_bucket, 'gnomad_hc.mt')\n",
    "gnomad_hc_mtf_path = join(work_bucket, 'gnomad_hc.filt.mt')\n",
    "gnomad_hc_mt21_path = join(work_bucket, 'gnomad_hc.chr21.mt')\n",
    "gnomad_hc_mt21f_path = join(work_bucket, 'gnomad_hc.chr21.filt.mt')\n",
    "# gnomad_mt.write(gnomad_mt_path, overwrite=True)\n",
    "# gnomad_mtf.write(gnomad_mtf_path, overwrite=True)\n",
    "# gnomad_mt21.write(gnomad_mt21_path, overwrite=True)\n",
    "# gnomad_mt21f.write(gnomad_mt21f_path, overwrite=True)\n",
    "# gnomad_mt_hc.write(gnomad_hc_mt_path, overwrite=True)\n",
    "# gnomad_mtf_hc.write(gnomad_hc_mtf_path, overwrite=True)\n",
    "# gnomad_mt21_hc.write(gnomad_hc_mt21_path, overwrite=True)\n",
    "# gnomad_mt21f_hc.write(gnomad_hc_mt21f_path, overwrite=True)\n",
    "gnomad_mt = hl.read_matrix_table(gnomad_mt_path)\n",
    "gnomad_mtf = hl.read_matrix_table(gnomad_mtf_path)\n",
    "gnomad_mt21 = hl.read_matrix_table(gnomad_mt21_path)\n",
    "gnomad_mt21f = hl.read_matrix_table(gnomad_mt21f_path)\n",
    "gnomad_hc_mt = hl.read_matrix_table(gnomad_hc_mt_path)\n",
    "gnomad_hc_mtf = hl.read_matrix_table(gnomad_hc_mtf_path)\n",
    "gnomad_hc_mt21 = hl.read_matrix_table(gnomad_hc_mt21_path)\n",
    "gnomad_hc_mt21f = hl.read_matrix_table(gnomad_hc_mt21f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-court",
   "metadata": {},
   "source": [
    "92% of gnomAD variants are PASSing, with 99% in the HC regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equivalent-mouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4640374, 4995085, 0.9289879951992809, 3559009, 3597730, 0.9892373802369827)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnomad_mtf.rows().count(), gnomad_mt.rows().count(), \\\n",
    "gnomad_mtf.rows().count() / gnomad_mt.rows().count(), \\\n",
    "gnomad_hc_mtf.rows().count(), gnomad_hc_mt.rows().count(), \\\n",
    "gnomad_hc_mtf.rows().count() / gnomad_hc_mt.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-composer",
   "metadata": {},
   "source": [
    "75% though in chr21:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "familiar-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67677, 89533, 0.7558888901298962, 51537, 51852, 0.9939250173570933)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnomad_mt21f.rows().count(), gnomad_mt21.rows().count(), \\\n",
    "gnomad_mt21f.rows().count() / gnomad_mt21.rows().count(), \\\n",
    "gnomad_hc_mt21f.rows().count(), gnomad_hc_mt21.rows().count(), \\\n",
    "gnomad_hc_mt21f.rows().count() / gnomad_hc_mt21.rows().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-spoke",
   "metadata": {},
   "source": [
    "### Exploring AS_VQSLOD in Gnomad MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "south-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_output()\n",
    "output_notebook()\n",
    "show(hl.plot.histogram(gnomad_mt21.aggregate_entries(hl.expr.aggregators.hist(gnomad_mt21.vqsr.AS_VQSLOD, -80, 30, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "convertible-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(hl.plot.histogram(gnomad_mt21f.aggregate_entries(hl.expr.aggregators.hist(gnomad_mt21f.vqsr.AS_VQSLOD, -80, 30, 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-virgin",
   "metadata": {},
   "source": [
    "### Evaluation: gnomad MT vs truth MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transparent-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 870, 533], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [155, 0, 0, 31558, 5], [33, 0, 0, 7, 20094]]\n",
      "Left = called: 51852\n",
      "Right = truth: 53067\n",
      "Unique to left = FP [precision]: 200 [99.61%]\n",
      "Unique to right = FN [recall]: 1415 [97.33%]\n",
      "Concordant = TP [discordant]: 51652 [12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 15:06:26 Hail: INFO: concordance: total concordance 99.98%\n"
     ]
    }
   ],
   "source": [
    "gn21_summary, gn_sample_conc_21ht, gn_sites_conc_21ht = hl.concordance(gnomad_hc_mt21, truth_mt21)\n",
    "print_conc_summary(gn21_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "gn_summary, gn_sample_concordance_ht, gn_sites_concordance_ht = hl.concordance(gnomad_hc_mt, truth_mt)\n",
    "print_conc_summary(gn_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cultural-strategy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------------+---------------------------+--------------------------+---------------------+---------------------------+\n",
       "| s               | bam_metrics.pct_bases_20x | bam_metrics.pct_chimeras | bam_metrics.freemix | bam_metrics.mean_coverage |\n",
       "+-----------------+---------------------------+--------------------------+---------------------+---------------------------+\n",
       "| str             |                   float64 |                  float64 |             float64 |                   float64 |\n",
       "+-----------------+---------------------------+--------------------------+---------------------+---------------------------+\n",
       "| \"v3.1::NA12878\" |                  9.47e+01 |                 6.83e-01 |            3.00e-06 |                  3.14e+01 |\n",
       "+-----------------+---------------------------+--------------------------+---------------------+---------------------------+\n",
       "\n",
       "+-----------------------------+------------------------------+--------------------------------+---------------------------+-------------+\n",
       "| bam_metrics.median_coverage | bam_metrics.mean_insert_size | bam_metrics.median_insert_size | bam_metrics.pct_bases_10x | subsets.tgp |\n",
       "+-----------------------------+------------------------------+--------------------------------+---------------------------+-------------+\n",
       "|                     float64 |                      float64 |                        float64 |                   float64 |        bool |\n",
       "+-----------------------------+------------------------------+--------------------------------+---------------------------+-------------+\n",
       "|                    3.20e+01 |                     4.42e+02 |                       4.33e+02 |                  9.71e+01 |        True |\n",
       "+-----------------------------+------------------------------+--------------------------------+---------------------------+-------------+\n",
       "\n",
       "+--------------+------------------------------+-----------------------------+-----------------------------+----------------------------+\n",
       "| subsets.hgdp | sex_imputation.chr20_mean_dp | sex_imputation.chrX_mean_dp | sex_imputation.chrY_mean_dp | sex_imputation.chrX_ploidy |\n",
       "+--------------+------------------------------+-----------------------------+-----------------------------+----------------------------+\n",
       "|         bool |                      float32 |                     float32 |                     float32 |                    float32 |\n",
       "+--------------+------------------------------+-----------------------------+-----------------------------+----------------------------+\n",
       "|        False |                     3.25e+01 |                    2.98e+01 |                    8.12e-01 |                   1.83e+00 |\n",
       "+--------------+------------------------------+-----------------------------+-----------------------------+----------------------------+\n",
       "\n",
       "+----------------------------+----------------------------+----------------------------+------------------------------+\n",
       "| sex_imputation.chrY_ploidy | sex_imputation.X_karyotype | sex_imputation.Y_karyotype | sex_imputation.sex_karyotype |\n",
       "+----------------------------+----------------------------+----------------------------+------------------------------+\n",
       "|                    float32 | str                        | str                        | str                          |\n",
       "+----------------------------+----------------------------+----------------------------+------------------------------+\n",
       "|                   5.01e-02 | \"XX\"                       | \"\"                         | \"XX\"                         |\n",
       "+----------------------------+----------------------------+----------------------------+------------------------------+\n",
       "\n",
       "+----------------------------------------+------------------------------------------+------------------------------------------+\n",
       "| sex_imputation.impute_sex_stats.f_stat | sex_imputation.impute_sex_stats.n_called | sex_imputation.impute_sex_stats.expec... |\n",
       "+----------------------------------------+------------------------------------------+------------------------------------------+\n",
       "|                                float64 |                                    int64 |                                  float64 |\n",
       "+----------------------------------------+------------------------------------------+------------------------------------------+\n",
       "|                              -1.23e+00 |                                    27087 |                                 1.88e+04 |\n",
       "+----------------------------------------+------------------------------------------+------------------------------------------+\n",
       "\n",
       "+------------------------------------------+---------------------+-----------------+---------------------+---------------------+\n",
       "| sex_imputation.impute_sex_stats.obser... | sample_qc.n_hom_ref | sample_qc.n_het | sample_qc.n_hom_var | sample_qc.n_non_ref |\n",
       "+------------------------------------------+---------------------+-----------------+---------------------+---------------------+\n",
       "|                                    int64 |               int64 |           int64 |               int64 |               int64 |\n",
       "+------------------------------------------+---------------------+-----------------+---------------------+---------------------+\n",
       "|                                     8538 |             4981521 |         1372005 |              662914 |             2034919 |\n",
       "+------------------------------------------+---------------------+-----------------+---------------------+---------------------+\n",
       "\n",
       "+-----------------+-----------------------+----------------------+------------------------+--------------------------+-------------------+\n",
       "| sample_qc.n_snp | sample_qc.n_insertion | sample_qc.n_deletion | sample_qc.n_transition | sample_qc.n_transversion | sample_qc.r_ti_tv |\n",
       "+-----------------+-----------------------+----------------------+------------------------+--------------------------+-------------------+\n",
       "|           int64 |                 int64 |                int64 |                  int64 |                    int64 |           float64 |\n",
       "+-----------------+-----------------------+----------------------+------------------------+--------------------------+-------------------+\n",
       "|         2572901 |                 27002 |                97930 |                1883215 |                   689686 |          2.73e+00 |\n",
       "+-----------------+-----------------------+----------------------+------------------------+--------------------------+-------------------+\n",
       "\n",
       "+-------------------------+--------------------------------+------------------------------------------+--------------------------+\n",
       "| sample_qc.r_het_hom_var | sample_qc.r_insertion_deletion | population_inference.pca_scores          | population_inference.pop |\n",
       "+-------------------------+--------------------------------+------------------------------------------+--------------------------+\n",
       "|                 float64 |                        float64 | array<float64>                           | str                      |\n",
       "+-------------------------+--------------------------------+------------------------------------------+--------------------------+\n",
       "|                2.07e+00 |                       2.76e-01 | [1.14e-01,-3.90e-02,9.31e-03,-2.04e-0... | \"nfe\"                    |\n",
       "+-------------------------+--------------------------------+------------------------------------------+--------------------------+\n",
       "\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "| population_inference.prob_afr | population_inference.prob_ami | population_inference.prob_amr | population_inference.prob_asj |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "|                       float64 |                       float64 |                       float64 |                       float64 |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "|                      0.00e+00 |                      0.00e+00 |                      0.00e+00 |                      0.00e+00 |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "| population_inference.prob_eas | population_inference.prob_fin | population_inference.prob_mid | population_inference.prob_nfe |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "|                       float64 |                       float64 |                       float64 |                       float64 |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "|                      0.00e+00 |                      0.00e+00 |                      0.00e+00 |                      1.00e+00 |\n",
       "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n",
       "\n",
       "+-------------------------------+-------------------------------+----------------+----------------+\n",
       "| population_inference.prob_oth | population_inference.prob_sas | labeled_subpop | gnomad_release |\n",
       "+-------------------------------+-------------------------------+----------------+----------------+\n",
       "|                       float64 |                       float64 | str            |           bool |\n",
       "+-------------------------------+-------------------------------+----------------+----------------+\n",
       "|                      0.00e+00 |                      0.00e+00 | \"ceu\"          |          False |\n",
       "+-------------------------------+-------------------------------+----------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnomad_mt21f.cols().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-tract",
   "metadata": {},
   "source": [
    "Filtered gnomad MT vs truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "violent-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:40:37 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-26 11:40:38 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 994, 586], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [18, 0, 0, 31435, 4], [32, 0, 0, 6, 20042]]\n",
      "Left = called: 51537\n",
      "Right = truth: 53067\n",
      "Unique to left = FP [precision]: 60 [99.88%]\n",
      "Unique to right = FN [recall]: 1590 [97.00%]\n",
      "Concordant = TP [discordant]: 51477 [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:40:51 Hail: INFO: concordance: total concordance 99.98%\n"
     ]
    }
   ],
   "source": [
    "gnf21_summary, _, g_ = hl.concordance(gnomad_hc_mt21f, truth_mt21)\n",
    "print_conc_summary(gnf21_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnffull_truth_summary, _, _ = hl.concordance(gnomad_hc_mtf, truth_mt)\n",
    "print_conc_summary(gnffull_truth_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-circular",
   "metadata": {},
   "source": [
    "### Evaluation: filtered gnomad MT vs filtered MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "spatial-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:40:52 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-26 11:40:52 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'inbreeding_coeff_cutoff' -> 'inbreeding_coeff_cutoff_1'\n",
      "    'filtering_model' -> 'filtering_model_1'\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "[[0, 0, 0, 93, 30], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [486, 0, 0, 30971, 0], [289, 0, 0, 1, 19790]]\n",
      "Left = called: 51537\n",
      "Right = truth: 50885\n",
      "Unique to left = FP [precision]: 776 [98.49%]\n",
      "Unique to right = FN [recall]: 124 [99.76%]\n",
      "Concordant = TP [discordant]: 50761 [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:41:04 Hail: INFO: concordance: total concordance 100.00%\n"
     ]
    }
   ],
   "source": [
    "gnf_summary, _, _ = hl.concordance(gnomad_hc_mt21f, mt21f_hc)\n",
    "print_conc_summary(gnf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnffull_summary, _, _ = hl.concordance(gnomad_hc_mtf, mtf_hc)\n",
    "print_conc_summary(gnffull_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-front",
   "metadata": {},
   "source": [
    "# Binned concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "veterinary-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 07:35:06 Hail: INFO: concordance: including 0 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-27 07:35:06 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n",
      "2021-07-27 07:37:28 Hail: INFO: concordance: total concordance nan%\n",
      "2021-07-27 07:37:28 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2021-07-27 07:37:29 Hail: INFO: concordance: including 1 shared samples (1 total on left, 1 total on right)\n",
      "2021-07-27 07:37:29 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'locus' -> 'locus_1'\n",
      "    'alleles' -> 'alleles_1'\n",
      "2021-07-27 07:37:44 Hail: INFO: concordance: total concordance 99.96%\n"
     ]
    }
   ],
   "source": [
    "_, gn_sample_conc_ht, gn_sites_conc_ht = hl.concordance(gnomad_hc_mt, truth_mt)\n",
    "_, samples_conc_ht, sites_conc_ht = hl.concordance(mt_hc, truth_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "possible-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 07:38:37 Hail: INFO: wrote table with 3687842 rows in 9718 partitions to gs://cpg-tob-wgs-test-tmp/concordance/tmp/sites_concordance.ht\n",
      "    Total size: 61.72 MiB\n",
      "    * Rows: 61.72 MiB\n",
      "    * Globals: 235.00 B\n",
      "    * Smallest partition: 0 rows (21.00 B)\n",
      "    * Largest partition:  1979 rows (31.00 KiB)\n"
     ]
    }
   ],
   "source": [
    "sites_conc_ht_path = join(work_bucket, 'sites_concordance.ht')\n",
    "samples_conc_ht_path = join(work_bucket, 'sample_concordance.ht')\n",
    "gn_sites_conc_ht_path = join(work_bucket, 'gn_sites_concordance.ht')\n",
    "gn_samples_conc_ht_path = join(work_bucket, 'gn_sample_concordance.ht')\n",
    "sites_conc_ht.write(sites_conc_ht_path, overwrite=True)\n",
    "sample_conc_ht.write(samples_conc_ht_path, overwrite=True)\n",
    "gn_sites_conc_ht.write(gn_sites_conc_ht_path, overwrite=True)\n",
    "gn_sample_conc_ht.write(gn_samples_conc_ht_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_conc_ht = hl.read_table(sites_conc_ht_path)\n",
    "sample_conc_ht = hl.read_table(sample_conc_ht_path)\n",
    "gn_sites_conc_ht = hl.read_table(gn_sites_conc_ht_path)\n",
    "gn_sample_conc_ht = hl.read_table(gn_sample_conc_ht_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-apple",
   "metadata": {},
   "source": [
    "### Rank variants (sort by the score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad_mt21.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "rural-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_variants(\n",
    "    mt,\n",
    "    model='CPG-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    "):\n",
    "    score_rank_ht_path = join(work_bucket, 'vqsr', model, truth_sample, 'score_rank.ht')\n",
    "    if not overwrite and utils.file_exists(score_rank_ht_path):\n",
    "        score_rank_ht = hl.read_table(score_rank_ht_path)\n",
    "        return score_rank_ht\n",
    "    print(f\"Creating rank file for VQSR\")\n",
    "    ht = mt.rows()\n",
    "    print('Filtering to high_quality samples and n_nonref==1...')\n",
    "    if 'was_split' not in ht._fields:\n",
    "        ht = ht.annotate(was_split = True)\n",
    "    if 'singleton' not in ht._fields:\n",
    "        ht = ht.annotate(singleton = True)\n",
    "    if 'ac' not in ht._fields:\n",
    "        ht = ht.annotate(ac = ht.gnomad_popmax.AC)\n",
    "    ht = ht.select(\n",
    "        was_split=ht.was_split,\n",
    "        singleton=ht.singleton,\n",
    "        ac=ht.ac,\n",
    "        score=ht.vqsr.AS_VQSLOD, \n",
    "        negative_train_site=ht.vqsr.NEGATIVE_TRAIN_SITE,\n",
    "        positive_train_site=ht.vqsr.POSITIVE_TRAIN_SITE,\n",
    "        culprit=ht.vqsr.AS_culprit\n",
    "    )\n",
    "\n",
    "    ht = add_rank(\n",
    "        ht,\n",
    "        score_expr=-1 * ht.score,\n",
    "        subrank_expr={\n",
    "            'biallelic_rank': ~ht.was_split,\n",
    "            'biallelic_singleton_rank': ~ht.was_split & ht.singleton,\n",
    "            'adj_rank': ht.ac > 0,\n",
    "            'adj_biallelic_rank': ~ht.was_split & (ht.ac > 0),\n",
    "            'adj_singleton_rank': ht.singleton & (ht.ac > 0),\n",
    "            'adj_biallelic_singleton_rank': ~ht.was_split & ht.singleton & (ht.ac > 0)\n",
    "        }\n",
    "    )\n",
    "    ht.write(score_rank_ht_path, overwrite=True)\n",
    "    score_rank_ht = hl.read_table(score_rank_ht_path)\n",
    "    return score_rank_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "younger-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rank file for VQSR\n",
      "Filtering to high_quality samples and n_nonref==1...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+----------------+------------+-------+\n",
       "| locus          | alleles    |    ac |\n",
       "+----------------+------------+-------+\n",
       "| locus<GRCh38>  | array<str> | int32 |\n",
       "+----------------+------------+-------+\n",
       "| chr21:10270435 | [\"G\",\"A\"]  |  3541 |\n",
       "| chr21:10270437 | [\"C\",\"G\"]  |  3400 |\n",
       "| chr21:10270443 | [\"T\",\"A\"]  |  3992 |\n",
       "| chr21:10270453 | [\"C\",\"A\"]  |  3777 |\n",
       "| chr21:10270455 | [\"A\",\"C\"]  |  3680 |\n",
       "| chr21:10270463 | [\"T\",\"C\"]  | 15347 |\n",
       "| chr21:10270466 | [\"T\",\"G\"]  |  3594 |\n",
       "| chr21:10270468 | [\"C\",\"T\"]  |  3338 |\n",
       "| chr21:10270473 | [\"G\",\"A\"]  |  3501 |\n",
       "| chr21:10270489 | [\"C\",\"T\"]  |  3372 |\n",
       "+----------------+------------+-------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 15:58:53 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-26 15:58:56 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-26 15:59:23 Hail: INFO: wrote table with 51852 rows in 1461 partitions to gs://cpg-tob-wgs-test-tmp/concordance/tmp/vqsr/gnomAD-AS-VQSR/NA12878/score_rank.ht\n",
      "    Total size: 1.99 MiB\n",
      "    * Rows: 1.98 MiB\n",
      "    * Globals: 7.12 KiB\n",
      "    * Smallest partition: 0 rows (21.00 B)\n",
      "    * Largest partition:  179 rows (6.13 KiB)\n"
     ]
    }
   ],
   "source": [
    "cpg_score_rank_21ht = rank_variants(\n",
    "    mt21,\n",
    "    model='CPG-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")\n",
    "gnomad_score_rank_21ht = rank_variants(\n",
    "    gnomad_mt21,\n",
    "    model='gnomAD-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dying-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rank file for VQSR\n",
      "Filtering to high_quality samples and n_nonref==1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 06:46:39 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-27 06:47:01 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-27 06:47:50 Hail: INFO: wrote table with 3602324 rows in 9618 partitions to gs://cpg-tob-wgs-test-tmp/concordance/tmp/vqsr/CPG-AS-VQSR/NA12878/score_rank.ht\n",
      "    Total size: 133.35 MiB\n",
      "    * Rows: 133.35 MiB\n",
      "    * Globals: 235.00 B\n",
      "    * Smallest partition: 0 rows (21.00 B)\n",
      "    * Largest partition:  1963 rows (74.99 KiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rank file for VQSR\n",
      "Filtering to high_quality samples and n_nonref==1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 06:48:33 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-27 06:50:31 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-07-27 06:55:15 Hail: INFO: wrote table with 4995085 rows in 115375 partitions to gs://cpg-tob-wgs-test-tmp/concordance/tmp/vqsr/gnomAD-AS-VQSR/NA12878/score_rank.ht\n",
      "    Total size: 200.44 MiB\n",
      "    * Rows: 200.44 MiB\n",
      "    * Globals: 7.12 KiB\n",
      "    * Smallest partition: 0 rows (21.00 B)\n",
      "    * Largest partition:  1620 rows (56.42 KiB)\n"
     ]
    }
   ],
   "source": [
    "cpg_score_rank_ht = rank_variants(\n",
    "    mt,\n",
    "    model='CPG-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")\n",
    "gnomad_score_rank_ht = rank_variants(\n",
    "    gnomad_mt,\n",
    "    model='gnomAD-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-muslim",
   "metadata": {},
   "source": [
    "### Create binned concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "south-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "plain-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_concordance(\n",
    "    score_rank_ht,\n",
    "    sites_concordance_ht,\n",
    "    model='CPG-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=False,\n",
    "):\n",
    "    binned_concordance_ht_path = join(work_bucket, 'vqsr', model, truth_sample, 'binned_concordance.ht')\n",
    "    if not overwrite and utils.file_exists(binned_concordance_ht_path):\n",
    "        ht = hl.read_table(binned_concordance_ht_path)\n",
    "        return ht\n",
    "\n",
    "    ht = sites_concordance_ht  # union of mt and truth_mt sites\n",
    "    metric_ht = score_rank_ht\n",
    "\n",
    "    # Total number of SNPs and indels in the target matrix table\n",
    "    metric_snvs, metrics_indels = metric_ht.aggregate([\n",
    "        hl.agg.count_where(hl.is_snp(metric_ht.alleles[0], metric_ht.alleles[1])),\n",
    "        hl.agg.count_where(~hl.is_snp(metric_ht.alleles[0], metric_ht.alleles[1]))\n",
    "    ])\n",
    "\n",
    "    # Total number of SNPs and indels in the union\n",
    "    snvs, indels = ht.aggregate([\n",
    "        hl.agg.count_where(hl.is_snp(ht.alleles[0], ht.alleles[1])),\n",
    "        hl.agg.count_where(~hl.is_snp(ht.alleles[0], ht.alleles[1]))\n",
    "    ])\n",
    "\n",
    "    ht = ht.annotate_globals(\n",
    "        global_counts=hl.struct(snvs=metric_snvs, indels=metrics_indels),\n",
    "        counts=hl.struct(snvs=snvs, indels=indels)\n",
    "    )\n",
    "    \n",
    "    # Annotating the union table with the target table annotations \n",
    "    # (so the variants unique to truth won't have those score annotations)\n",
    "    ht = ht.annotate(\n",
    "        snv=hl.is_snp(ht.alleles[0], ht.alleles[1]),\n",
    "        score=metric_ht[ht.key].score,\n",
    "        global_rank=metric_ht[ht.key].rank,\n",
    "        # TP => allele is found in both data sets\n",
    "        n_tp=ht.concordance[3][3] + ht.concordance[3][4] + ht.concordance[4][3] + ht.concordance[4][4],\n",
    "        # FP => allele is found only in test data set\n",
    "        n_fp=hl.sum(ht.concordance[3][:2]) + hl.sum(ht.concordance[4][:2]),\n",
    "        # FN => allele is found only in truth data set\n",
    "        n_fn=hl.sum(ht.concordance[:2].map(lambda x: x[3] + x[4]))\n",
    "    )\n",
    "    \n",
    "    # Add ranks\n",
    "    ht = add_rank(ht, -1.0*ht.score)\n",
    "    ht = ht.annotate(rank=[\n",
    "        hl.tuple([\n",
    "            'global_rank', \n",
    "            (ht.global_rank + 1) / hl.cond(\n",
    "                 ht.snv,\n",
    "                 ht.globals.global_counts.snvs,\n",
    "                 ht.globals.global_counts.indels\n",
    "             )\n",
    "        ]),\n",
    "        hl.tuple([\n",
    "            'truth_sample_rank', \n",
    "            (ht.rank + 1) / hl.cond(\n",
    "                 ht.snv,\n",
    "                 ht.globals.counts.snvs,\n",
    "                 ht.globals.counts.indels\n",
    "             )\n",
    "        ])\n",
    "    ])\n",
    "    ht = ht.explode(ht.rank)\n",
    "    \n",
    "    ht = ht.annotate(\n",
    "        rank_name=ht.rank[0],\n",
    "        bin=hl.int(ht.rank[1] * nbins)\n",
    "    )\n",
    "\n",
    "    ht = ht.group_by(\n",
    "        'rank_name',\n",
    "        'snv',\n",
    "        'bin'\n",
    "    ).aggregate(\n",
    "        # Look at site-level metrics -> tp > fp > fn -- only important for multi-sample comparisons\n",
    "        tp=hl.agg.count_where(ht.n_tp > 0),\n",
    "        fp=hl.agg.count_where((ht.n_tp == 0) & (ht.n_fp > 0)),\n",
    "        fn=hl.agg.count_where((ht.n_tp == 0) & (ht.n_fp == 0) & (ht.n_fn > 0)),\n",
    "        min_score=hl.agg.min(ht.score),\n",
    "        max_score=hl.agg.max(ht.score),\n",
    "        n_alleles=hl.agg.count()\n",
    "    ).repartition(5)\n",
    "    \n",
    "    ht.show()\n",
    "\n",
    "    ht.write(binned_concordance_ht_path, overwrite=True)    \n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "coupled-sitting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binned_concordance(\n",
    "    cpg_score_rank_ht, \n",
    "    sites_conc_ht, \n",
    "    model='CPG-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")\n",
    "binned_concordance(\n",
    "    gnomad_score_rank_ht, \n",
    "    gn_sites_conc_ht, \n",
    "    model='gnomAD-AS-VQSR', \n",
    "    truth_sample=TRUTH_SAMPLE,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "enhanced-fireplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 10:51:39 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+---------------------+-------+-------+--------+--------+-------+-----------+-----------+-----------+\n",
       "| rank_name           |   snv |   bin |     tp |     fp |    fn | min_score | max_score | n_alleles |\n",
       "+---------------------+-------+-------+--------+--------+-------+-----------+-----------+-----------+\n",
       "| str                 |  bool | int32 |  int64 |  int64 | int64 |   float64 |   float64 |     int64 |\n",
       "+---------------------+-------+-------+--------+--------+-------+-----------+-----------+-----------+\n",
       "| \"global_rank\"       | False |     0 | 166542 |  40866 |     0 |  3.65e+00 |  1.80e+01 |    207408 |\n",
       "| \"global_rank\"       | False |     1 | 107259 | 100150 |     0 | -6.91e+02 |  3.65e+00 |    207409 |\n",
       "| \"global_rank\"       | False |     2 |  99761 | 107648 |     0 |        NA |        NA |    207409 |\n",
       "| \"global_rank\"       | False |     3 |  96278 | 111131 |     0 |        NA |        NA |    207409 |\n",
       "| \"global_rank\"       | False |     4 |  97126 | 110283 |     0 |        NA |        NA |    207409 |\n",
       "| \"global_rank\"       | False |     5 |      0 |      1 |     0 |        NA |        NA |         1 |\n",
       "| \"global_rank\"       | False |    NA |      0 |      0 |  4096 |        NA |        NA |      4096 |\n",
       "| \"global_rank\"       |  True |     0 | 745416 |  75104 |     0 |  5.88e+00 |  6.85e+00 |    820520 |\n",
       "| \"global_rank\"       |  True |     1 | 731242 |  89279 |     0 |  5.19e+00 |  5.88e+00 |    820521 |\n",
       "| \"global_rank\"       |  True |     2 | 717914 | 102607 |     0 |  4.00e+00 |  5.19e+00 |    820521 |\n",
       "| \"global_rank\"       |  True |     3 | 638308 | 182213 |     0 | -3.44e-01 |  4.00e+00 |    820521 |\n",
       "| \"global_rank\"       |  True |     4 | 252533 | 567987 |     0 | -4.00e+04 | -3.44e-01 |    820520 |\n",
       "| \"global_rank\"       |  True |     5 |      0 |      1 |     0 |        NA |        NA |         1 |\n",
       "| \"global_rank\"       |  True |    NA |      0 |      0 |  2894 |        NA |        NA |      2894 |\n",
       "| \"truth_sample_rank\" | False |     0 | 167174 |  41054 |     0 |  3.62e+00 |  1.80e+01 |    208228 |\n",
       "| \"truth_sample_rank\" | False |     1 | 109052 |  98791 |   385 | -6.91e+02 |  3.62e+00 |    208228 |\n",
       "| \"truth_sample_rank\" | False |     2 |  95620 | 111401 |  1207 |        NA |        NA |    208228 |\n",
       "| \"truth_sample_rank\" | False |     3 |  96049 | 110958 |  1221 |        NA |        NA |    208228 |\n",
       "| \"truth_sample_rank\" | False |     4 |  99070 | 107875 |  1283 |        NA |        NA |    208228 |\n",
       "| \"truth_sample_rank\" | False |     5 |      1 |      0 |     0 |        NA |        NA |         1 |\n",
       "| \"truth_sample_rank\" |  True |     0 | 745938 |  75161 |     0 |  5.88e+00 |  6.85e+00 |    821099 |\n",
       "| \"truth_sample_rank\" |  True |     1 | 731752 |  89348 |     0 |  5.19e+00 |  5.88e+00 |    821100 |\n",
       "| \"truth_sample_rank\" |  True |     2 | 718385 | 102714 |     0 |  4.00e+00 |  5.19e+00 |    821099 |\n",
       "| \"truth_sample_rank\" |  True |     3 | 637741 | 183359 |     0 | -3.97e-01 |  4.00e+00 |    821100 |\n",
       "| \"truth_sample_rank\" |  True |     4 | 251597 | 566608 |  2894 | -4.00e+04 | -3.97e-01 |    821099 |\n",
       "| \"truth_sample_rank\" |  True |     5 |      0 |      1 |     0 |        NA |        NA |         1 |\n",
       "+---------------------+-------+-------+--------+--------+-------+-----------+-----------+-----------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ht.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cubic-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binned_concordance_pd(\n",
    "    work_bucket: str,\n",
    "    model_names: List[str],\n",
    "    truth_samples: List[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a pandas DF containing the binned concordance results for all given truth samples / models.\n",
    "    :param list of str truth_samples: List of truth samples to include\n",
    "    :param list of str or dict of str -> str models: \n",
    "        Models to include. Either a list of the model ids, \n",
    "        or a dict with model id -> model name for display\n",
    "    :return: Pandas dataframe with binned concordance results\n",
    "    :rtype: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_binned_concordance_ht(model_name, truth_sample):\n",
    "        ht = hl.read_table(join(work_bucket, 'vqsr', model_name, truth_sample, 'binned_concordance.ht'))\n",
    "        try:\n",
    "            ht = ht.drop('global_annotation_descriptions')\n",
    "        except:\n",
    "            pass\n",
    "        ht = ht.annotate_globals(\n",
    "            filtering_model = ht.filtering_model.annotate(\n",
    "                snv_cutoff = ht.filtering_model.snv_cutoff.annotate(\n",
    "                    bin = hl.float(ht.filtering_model.snv_cutoff.bin)\n",
    "                ),\n",
    "                indel_cutoff = ht.filtering_model.indel_cutoff.annotate(\n",
    "                    bin = hl.float(ht.filtering_model.indel_cutoff.bin)\n",
    "                ),\n",
    "            )\n",
    "        )    \n",
    "        return ht\n",
    "    \n",
    "    # Combine binned concordance results for multiple truth samples and/or models into a single Table.\n",
    "    hts = []\n",
    "    for truth_sample in truth_samples:\n",
    "        for model_name in model_names:\n",
    "            ht = get_binned_concordance_ht(model_name, truth_sample)\n",
    "            ht = ht.annotate(truth_sample=truth_sample, model=model_name)\n",
    "            hts.append(ht)\n",
    "    ht = hts[0].union(*hts[1:])\n",
    "\n",
    "    def f_score(n, df):\n",
    "        return (1 + n**2) * df['precision'] * df['recall'] / (n**2 * df['precision'] + df['recall'])\n",
    "\n",
    "    def compute_cumul_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes cumulative metrics on a pandas DF.\n",
    "        \"\"\"\n",
    "        df = df.sort_values(by=['bin'])\n",
    "        df['cum_tp'] = df['tp'].cumsum()\n",
    "        df['cum_fp'] = df['fp'].cumsum()\n",
    "        total_true = df['tp'].sum() + df['fn'].sum()\n",
    "        total_false = df['fp'].sum()\n",
    "        df['cum_fn'] = total_true - df['cum_tp']\n",
    "        df['cum_tn'] = total_false - df['cum_fp']\n",
    "        df['precision'] = df['cum_tp'] / (df['cum_tp'] + df['cum_fp'])\n",
    "        df['recall'] = df['cum_tp'] / (df['cum_tp'] + df['cum_fn'])\n",
    "        df['cum_alleles'] = df['n_alleles'].cumsum()\n",
    "        df['f1'] = f_score(2, df)\n",
    "        df['f2'] = f_score(2, df)\n",
    "        df['f3'] = f_score(3, df)\n",
    "        df['f4'] = f_score(4, df)\n",
    "        df['f10'] = f_score(10, df)\n",
    "        return df[['bin', 'min_score', 'max_score', 'n_alleles', 'tp', 'fp', 'fn', 'cum_alleles', \n",
    "                   'cum_tp', 'cum_fp', 'cum_fn', 'cum_tn', 'precision', 'recall', \n",
    "                   'f1', 'f2', 'f3', 'f4', 'f10']]\n",
    "\n",
    "    df = ht.to_pandas()\n",
    "    df = df.groupby(['rank_name', 'truth_sample', 'model', 'snv']).apply(compute_cumul_metrics)\n",
    "    return df.fillna(-1).groupby(['rank_name', 'truth_sample', 'model', 'snv'])\n",
    "\n",
    "df = make_binned_concordance_pd(\n",
    "    work_bucket,\n",
    "    model_names=['CPG-AS-VQSR', 'gnomAD-AS-VQSR'],\n",
    "    truth_samples=[TRUTH_SAMPLE],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "democratic-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------------+-------+-------+-------+-------+-------+-----------+-----------+-----------+--------------+------------------+\n",
       "| rank_name     |   snv |   bin |    tp |    fp |    fn | min_score | max_score | n_alleles | truth_sample | model            |\n",
       "+---------------+-------+-------+-------+-------+-------+-----------+-----------+-----------+--------------+------------------+\n",
       "| str           |  bool | int32 | int64 | int64 | int64 |   float64 |   float64 |     int64 | str          | str              |\n",
       "+---------------+-------+-------+-------+-------+-------+-----------+-----------+-----------+--------------+------------------+\n",
       "| \"global_rank\" | False |     0 |    68 |     0 |     0 |  1.80e+01 |  1.80e+01 |        68 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     0 |    68 |     0 |     0 |  1.80e+01 |  1.80e+01 |        68 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     1 |    80 |     0 |     0 |  1.79e+01 |  1.80e+01 |        80 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     1 |    80 |     0 |     0 |  1.79e+01 |  1.80e+01 |        80 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     2 |    97 |     0 |     0 |  1.79e+01 |  1.79e+01 |        97 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     2 |    97 |     0 |     0 |  1.79e+01 |  1.79e+01 |        97 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     3 |    74 |     0 |     0 |  1.78e+01 |  1.79e+01 |        74 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     3 |    74 |     0 |     0 |  1.78e+01 |  1.79e+01 |        74 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     4 |    79 |     0 |     0 |  1.78e+01 |  1.78e+01 |        79 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     4 |    79 |     0 |     0 |  1.78e+01 |  1.78e+01 |        79 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     5 |    80 |     0 |     0 |  1.77e+01 |  1.78e+01 |        80 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     5 |    80 |     0 |     0 |  1.77e+01 |  1.78e+01 |        80 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     6 |    91 |     0 |     0 |  1.77e+01 |  1.77e+01 |        91 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     6 |    91 |     0 |     0 |  1.77e+01 |  1.77e+01 |        91 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     7 |    92 |     0 |     0 |  1.76e+01 |  1.77e+01 |        92 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     7 |    92 |     0 |     0 |  1.76e+01 |  1.77e+01 |        92 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     8 |    73 |     0 |     0 |  1.76e+01 |  1.76e+01 |        73 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     8 |    73 |     0 |     0 |  1.76e+01 |  1.76e+01 |        73 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |     9 |    82 |     0 |     0 |  1.75e+01 |  1.76e+01 |        82 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |     9 |    82 |     0 |     0 |  1.75e+01 |  1.76e+01 |        82 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    10 |   100 |     0 |     0 |  1.74e+01 |  1.75e+01 |       100 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    10 |   100 |     0 |     0 |  1.74e+01 |  1.75e+01 |       100 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    11 |    80 |     0 |     0 |  1.74e+01 |  1.74e+01 |        80 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    11 |    80 |     0 |     0 |  1.74e+01 |  1.74e+01 |        80 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    12 |    77 |     0 |     0 |  1.73e+01 |  1.74e+01 |        77 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    12 |    77 |     0 |     0 |  1.73e+01 |  1.74e+01 |        77 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    13 |    95 |     0 |     0 |  1.72e+01 |  1.73e+01 |        95 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    13 |    95 |     0 |     0 |  1.72e+01 |  1.73e+01 |        95 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    14 |    89 |     0 |     0 |  1.71e+01 |  1.72e+01 |        89 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    14 |    89 |     0 |     0 |  1.71e+01 |  1.72e+01 |        89 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    15 |    94 |     0 |     0 |  1.70e+01 |  1.71e+01 |        94 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    15 |    94 |     0 |     0 |  1.70e+01 |  1.71e+01 |        94 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    16 |    64 |     0 |     0 |  1.68e+01 |  1.70e+01 |        64 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    16 |    64 |     0 |     0 |  1.68e+01 |  1.70e+01 |        64 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    17 |    78 |     1 |     0 |  1.66e+01 |  1.68e+01 |        79 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    17 |    78 |     1 |     0 |  1.66e+01 |  1.68e+01 |        79 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    18 |    70 |     0 |     0 |  1.65e+01 |  1.66e+01 |        70 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    18 |    70 |     0 |     0 |  1.65e+01 |  1.66e+01 |        70 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    19 |    77 |     1 |     0 |  1.64e+01 |  1.65e+01 |        78 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    19 |    77 |     1 |     0 |  1.64e+01 |  1.65e+01 |        78 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    20 |    76 |     0 |     0 |  1.64e+01 |  1.64e+01 |        76 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    20 |    76 |     0 |     0 |  1.64e+01 |  1.64e+01 |        76 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    21 |    87 |     0 |     0 |  1.63e+01 |  1.64e+01 |        87 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    21 |    87 |     0 |     0 |  1.63e+01 |  1.64e+01 |        87 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    22 |    72 |     1 |     0 |  1.62e+01 |  1.63e+01 |        73 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    22 |    72 |     1 |     0 |  1.62e+01 |  1.63e+01 |        73 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    23 |    70 |     0 |     0 |  1.61e+01 |  1.62e+01 |        70 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    23 |    70 |     0 |     0 |  1.61e+01 |  1.62e+01 |        70 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "| \"global_rank\" | False |    24 |    77 |     0 |     0 |  1.60e+01 |  1.61e+01 |        77 | \"NA12878\"    | \"CPG-AS-VQSR\"    |\n",
       "| \"global_rank\" | False |    24 |    77 |     0 |     0 |  1.60e+01 |  1.61e+01 |        77 | \"NA12878\"    | \"gnomAD-AS-VQSR\" |\n",
       "+---------------+-------+-------+-------+-------+-------+-----------+-----------+-----------+--------------+------------------+\n"      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ht.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incomplete-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_plots_settings = {\n",
    "    'mean_point_size': 4.0,\n",
    "    'min_point_size': 1.0,\n",
    "    'max_point_size': 16.0,\n",
    "    'label_text_font_size': \"14pt\",\n",
    "    'title.text_font_size': \"16pt\",\n",
    "    'subtitle.text_font_size': \"14pt\",\n",
    "    'axis.axis_label_text_font_size': \"16pt\",\n",
    "    'axis.axis_label_text_font_style': \"normal\",\n",
    "    'axis.major_label_text_font_size': \"14pt\"\n",
    "}\n",
    "\n",
    "def set_plots_defaults(p: Plot) -> None:\n",
    "    p.legend.label_text_font_size = qc_plots_settings['label_text_font_size']\n",
    "    p.title.text_font_size = qc_plots_settings['title.text_font_size']\n",
    "    p.axis.axis_label_text_font_size = qc_plots_settings['axis.axis_label_text_font_size']\n",
    "    p.axis.axis_label_text_font_style = qc_plots_settings['axis.axis_label_text_font_style']\n",
    "    p.axis.major_label_text_font_size = qc_plots_settings['axis.major_label_text_font_size']\n",
    "\n",
    "def get_point_size_col(data: pd.Series, size_prop: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a data Series, returns the corresponding point size either:\n",
    "    - Constant to qc_plots_settings['mean_point_size'] if `size_prop` is None\n",
    "    - Radius proportional to data, if `size_prop` is 'radius'\n",
    "    - Area proportional to data, if `size_prop` is 'area'\n",
    "    Mean, min and max point  sizes are extracted from qc_plots_settings\n",
    "    :param Series data: Input data series\n",
    "    :param str size_prop: One of None, 'radius' or 'area'\n",
    "    :return: Series with corresponding point size for each data point\n",
    "    :rtype: Series\n",
    "    \"\"\"\n",
    "    if size_prop is None:\n",
    "        return pd.Series(len(data) * [qc_plots_settings['mean_point_size']])\n",
    "    else:\n",
    "        mean_data = np.mean(data)\n",
    "        if size_prop == 'radius':\n",
    "            return data.apply(lambda x: max(qc_plots_settings['min_point_size'], \n",
    "                                            min(qc_plots_settings['max_point_size'], \n",
    "                                                qc_plots_settings['mean_point_size'] * (x / mean_data))))\n",
    "        elif size_prop == 'area':\n",
    "            return data.apply(\n",
    "                lambda x: max(\n",
    "                    qc_plots_settings['min_point_size'], \n",
    "                    min(\n",
    "                        qc_plots_settings['max_point_size'], \n",
    "                        qc_plots_settings['mean_point_size'] * np.pi * (np.sqrt(x / mean_data) / np.pi)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{size_prop} is not a supported value for argument `size_prop`\")\n",
    "            \n",
    "def plot_concordance_pr(\n",
    "    pr_df: pd.DataFrame,\n",
    "    snv: bool,\n",
    "    colors: Dict[str, str] = None,\n",
    "    size_prop: str = None,\n",
    "    bins_to_label: List[int] = None\n",
    ") -> Column:\n",
    "    \"\"\"\n",
    "    Generates plots showing Precision/Recall curves for truth samples:\n",
    "    Two tabs:\n",
    "    - One displaying the PR curve with ranking computed on the entire data\n",
    "    - One displaying the PR curve with ranking computed on the truth sample only\n",
    "\n",
    "    Within each tab, a row of n_truth_samples.\n",
    "    The input to this function should come out of the `get_binned_concordance_pd` function, \n",
    "    which creates  a DataFrame containing the necessary metris for PR plotting and is grouped \n",
    "    by 'rank_name', 'truth_sample', 'model' and 'snv'.\n",
    "    :param DataFrame pr_df: \n",
    "           Input Dataframe\n",
    "    :param bool snv: \n",
    "           Whether to plot SNVs or Indels\n",
    "    :param dict of str -> str colors: \n",
    "           Optional colors to use (model name -> desired color)\n",
    "    :param str size_prop: \n",
    "           Either 'radius' or 'area' can be specified. If either is specified, \n",
    "           the points will be sized proportionally to the amount of data in that point.\n",
    "    :param list of int bins_to_label: \n",
    "           Bins to label\n",
    "    :return Bokeh grid of plots\n",
    "    :rtype Tabs\n",
    "    \"\"\"\n",
    "\n",
    "    if colors is None:\n",
    "        # Get a palette automatically\n",
    "        from bokeh.palettes import d3\n",
    "        models = sorted(list(set([g[2] for g in pr_df.groups])))\n",
    "        palette = d3['Category10'][max(3, len(models))]\n",
    "        colors = {model: palette[i] for i, model in enumerate(models)}\n",
    "\n",
    "    tabs = []\n",
    "    rank = 'global_rank'  # 'truth_sample_rank',\n",
    "#         plot_row = []\n",
    "#         for truth_sample in set([g[1] for g in pr_df.groups]):\n",
    "#             hover = HoverTool(tooltips=[\n",
    "#                     (\"model\", \"@model\"),\n",
    "#                     (\"bin\", \"@bin\"),\n",
    "#                     (\"score (min, max)\", \"(@min_score, @max_score)\"),\n",
    "#                     ('n_alleles', '@n_alleles'),\n",
    "#                     ('cum_alleles', '@cum_alleles'),\n",
    "#                     (\"data (x,y)\", \"($x, $y)\")\n",
    "#                 ],\n",
    "#                 mode='vline'\n",
    "#             )\n",
    "    TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\".split(',')\n",
    "\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"model\", \"@model\"),\n",
    "            (\"bin\", \"@bin\"),\n",
    "            (\"score (min, max)\", \"(@min_score, @max_score)\"),\n",
    "            ('n_alleles', '@n_alleles'),\n",
    "            ('cum_alleles', '@cum_alleles'),\n",
    "            ('recall', '@recall'),\n",
    "            ('precision', '@precision'),\n",
    "            ('cum_fp', '@cum_fp'),\n",
    "            ('cum_tp', '@cum_tp'),\n",
    "            ('cum_fn', '@cum_fn'),\n",
    "            ('f1', '@f1'),\n",
    "            ('f2', '@f2'),\n",
    "        ],\n",
    "        # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "        mode='vline'\n",
    "    )\n",
    "    p = figure(\n",
    "        title=TRUTH_SAMPLE,\n",
    "        x_axis_label='Recall',\n",
    "        y_axis_label='Precision',\n",
    "        tools=[hover] + [tool for tool in TOOLS if tool != 'hover'],\n",
    "#         x_range=(0, 1.05), \n",
    "#         y_range=(0, 1)\n",
    "    )\n",
    "    p.xaxis[0].formatter = NumeralTickFormatter(format=\"0%\")\n",
    "    p.yaxis[0].formatter = NumeralTickFormatter(format=\"0.0%\")\n",
    "\n",
    "    circles = []\n",
    "    for model in set([g[2] for g in pr_df.groups]):\n",
    "        data = pr_df.get_group((rank, TRUTH_SAMPLE, model, snv)).copy()\n",
    "        data['model'] = [model] * len(data)\n",
    "        data['size'] = get_point_size_col(data['n_alleles'], size_prop)\n",
    "        data['x_offset'] = data['recall'] + 0.025\n",
    "        data['y_offset'] = data['precision']\n",
    "        data['f2'] = [str(\"{:.2f}\".format(t)) for t in data['f2']]\n",
    "        source = ColumnDataSource(data)\n",
    "        if bins_to_label is not None:\n",
    "            label_data = data.copy()\n",
    "            label_data = label_data.loc[label_data.bin.isin(bins_to_label)].copy()\n",
    "            label_data = ColumnDataSource(label_data)\n",
    "            p.circle(\n",
    "                'recall',\n",
    "                'precision',\n",
    "                color=colors[model], \n",
    "                source=label_data\n",
    "            )\n",
    "            p.add_layout(\n",
    "                LabelSet(\n",
    "                    x='x_offset',\n",
    "                    y='precision',\n",
    "                    text='f2',\n",
    "                    text_font_size='6pt',\n",
    "                    x_offset=-10, \n",
    "                    y_offset=1,\n",
    "                    text_color=colors[model],\n",
    "                    source=label_data\n",
    "                )\n",
    "            )\n",
    "        p.line(\n",
    "            'recall',\n",
    "            'precision',\n",
    "            source=source,\n",
    "            line_width=2,\n",
    "        )\n",
    "#             p.tools = [hover] + [tool for tool in TOOLS if tool != 'hover']\n",
    "#     set_plots_defaults(p)\n",
    "    return p\n",
    "#         tabs.append(Panel(child=Row(children=plot_row), title=rank))\n",
    "#     return Tabs(tabs=tabs)\n",
    "\n",
    "# nbins // 20\n",
    "p = plot_concordance_pr(df, snv=True, bins_to_label=range(0, nbins + 1, 1))\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "secondary-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                bin  min_score  max_score  \\\n",
       "rank_name         truth_sample model snv                                    \n",
       "global_rank       NA12878      VQSR  False 0    0.0    17.9027    18.0431   \n",
       "                                           1    1.0    17.8035    17.9027   \n",
       "                                           2    2.0    17.6876    17.8035   \n",
       "                                           3    3.0    17.5437    17.6876   \n",
       "                                           4    4.0    17.3570    17.5436   \n",
       "                                     True  102  0.0     6.6075     6.8471   \n",
       "                                           103  1.0     6.5465     6.6075   \n",
       "                                           104  2.0     6.4959     6.5465   \n",
       "                                           105  3.0     6.4502     6.4959   \n",
       "                                           106  4.0     6.4069     6.4502   \n",
       "truth_sample_rank NA12878      VQSR  False 204  0.0    17.9023    18.0431   \n",
       "                                           205  1.0    17.8026    17.9023   \n",
       "                                           206  2.0    17.6861    17.8025   \n",
       "                                           207  3.0    17.5413    17.6860   \n",
       "                                           208  4.0    17.3530    17.5413   \n",
       "                                     True  305  0.0     6.6075     6.8471   \n",
       "                                           306  1.0     6.5464     6.6075   \n",
       "                                           307  2.0     6.4958     6.5464   \n",
       "                                           308  3.0     6.4501     6.4958   \n",
       "                                           309  4.0     6.4068     6.4501   \n",
       "\n",
       "                                                n_alleles     tp    fp  fn  \\\n",
       "rank_name         truth_sample model snv                                     \n",
       "global_rank       NA12878      VQSR  False 0        10370   8881  1489   0   \n",
       "                                           1        10370   8917  1453   0   \n",
       "                                           2        10371   8952  1419   0   \n",
       "                                           3        10370   8918  1452   0   \n",
       "                                           4        10371   8945  1426   0   \n",
       "                                     True  102      41026  37549  3477   0   \n",
       "                                           103      41026  37506  3520   0   \n",
       "                                           104      41026  37538  3488   0   \n",
       "                                           105      41026  37469  3557   0   \n",
       "                                           106      41026  37513  3513   0   \n",
       "truth_sample_rank NA12878      VQSR  False 204      10411   8914  1497   0   \n",
       "                                           205      10411   8958  1453   0   \n",
       "                                           206      10412   8984  1428   0   \n",
       "                                           207      10411   8958  1453   0   \n",
       "                                           208      10412   8971  1441   0   \n",
       "                                     True  305      41054  37574  3480   0   \n",
       "                                           306      41055  37533  3522   0   \n",
       "                                           307      41055  37563  3492   0   \n",
       "                                           308      41055  37500  3555   0   \n",
       "                                           309      41055  37531  3524   0   \n",
       "\n",
       "                                                cum_alleles  cum_tp  cum_fp  \\\n",
       "rank_name         truth_sample model snv                                      \n",
       "global_rank       NA12878      VQSR  False 0          10370    8881    1489   \n",
       "                                           1          20740   17798    2942   \n",
       "                                           2          31111   26750    4361   \n",
       "                                           3          41481   35668    5813   \n",
       "                                           4          51852   44613    7239   \n",
       "                                     True  102        41026   37549    3477   \n",
       "                                           103        82052   75055    6997   \n",
       "                                           104       123078  112593   10485   \n",
       "                                           105       164104  150062   14042   \n",
       "                                           106       205130  187575   17555   \n",
       "truth_sample_rank NA12878      VQSR  False 204        10411    8914    1497   \n",
       "                                           205        20822   17872    2950   \n",
       "                                           206        31234   26856    4378   \n",
       "                                           207        41645   35814    5831   \n",
       "                                           208        52057   44785    7272   \n",
       "                                     True  305        41054   37574    3480   \n",
       "                                           306        82109   75107    7002   \n",
       "                                           307       123164  112670   10494   \n",
       "                                           308       164219  150170   14049   \n",
       "                                           309       205274  187701   17573   \n",
       "\n",
       "                                                 cum_fn   cum_tn  precision  \\\n",
       "rank_name         truth_sample model snv                                      \n",
       "global_rank       NA12878      VQSR  False 0     562181   468590   0.856413   \n",
       "                                           1     553264   467137   0.858149   \n",
       "                                           2     544312   465718   0.859824   \n",
       "                                           3     535394   464266   0.859864   \n",
       "                                           4     526449   462840   0.860391   \n",
       "                                     True  102  3050758  1013714   0.915249   \n",
       "                                           103  3013252  1010194   0.914725   \n",
       "                                           104  2975714  1006706   0.914810   \n",
       "                                           105  2938245  1003149   0.914432   \n",
       "                                           106  2900732   999636   0.914420   \n",
       "truth_sample_rank NA12878      VQSR  False 204   562148   468582   0.856210   \n",
       "                                           205   553190   467129   0.858323   \n",
       "                                           206   544206   465701   0.859832   \n",
       "                                           207   535248   464248   0.859983   \n",
       "                                           208   526277   462807   0.860307   \n",
       "                                     True  305  3050733  1013711   0.915234   \n",
       "                                           306  3013200  1010189   0.914723   \n",
       "                                           307  2975637  1006697   0.914797   \n",
       "                                           308  2938137  1003142   0.914450   \n",
       "                                           309  2900606   999618   0.914392   \n",
       "\n",
       "                                                  recall  \n",
       "rank_name         truth_sample model snv                  \n",
       "global_rank       NA12878      VQSR  False 0    0.015552  \n",
       "                                           1    0.031166  \n",
       "                                           2    0.046843  \n",
       "                                           3    0.062459  \n",
       "                                           4    0.078123  \n",
       "                                     True  102  0.012158  \n",
       "                                           103  0.024303  \n",
       "                                           104  0.036458  \n",
       "                                           105  0.048590  \n",
       "                                           106  0.060737  \n",
       "truth_sample_rank NA12878      VQSR  False 204  0.015610  \n",
       "                                           205  0.031296  \n",
       "                                           206  0.047028  \n",
       "                                           207  0.062715  \n",
       "                                           208  0.078424  \n",
       "                                     True  305  0.012167  \n",
       "                                           306  0.024320  \n",
       "                                           307  0.036483  \n",
       "                                           308  0.048625  \n",
       "                                           309  0.060778  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "published-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_to_label=range(0, nbins + 1, nbins // 20)\n",
    "data = df.get_group(('truth_sample_rank', truth_sample, 'VQSR', True)).copy()\n",
    "a = data.loc[data.bin.isin(bins_to_label)]\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
