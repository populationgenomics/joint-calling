include required(classpath("application"))
google {
  application-name = "cromwell"
  auths = [
    { 
      name = "service_account"
      scheme = "service_account"
      service-account-id = "785770243118-compute@developer.gserviceaccount.com"
      json-file = "/Users/vlad/vlad-dev-f2ee54c9aca4.json"
    }
  ]
}
engine {
  filesystems {
    gcs {
      auth = "service_account"
      project = "vlad-dev"
    }
  }
}
backend {
  default = "JES"

  providers {
    JES {
      actor-factory = "cromwell.backend.impl.jes.JesBackendLifecycleActorFactory"
      config {
        // Google project
        project = "vlad-dev"
        compute-service-account = "default"

        // Base bucket for workflow executions
        root = "gs://playground-us/cpg_qc/wdl"

        // Polling for completion backs-off gradually for slower-running jobs.
        // This is the maximum polling interval (in seconds):
        maximum-polling-interval = 600

        // Optional Dockerhub Credentials. Can be used to access private docker images.
        genomics {
          // A reference to an auth defined in the `google` stanza at the top.  This auth is used to create
          // Pipelines and manipulate auth JSONs.
          auth = "service_account"
          // Endpoint for APIs, no reason to change this unless directed by Google.
          endpoint-url = "https://genomics.googleapis.com/"
          // This allows you to use an alternative service account to launch jobs, by default uses default service account
          compute-service-account = "default"
        }
        filesystems {
          gcs {
            // A reference to a potentially different auth for manipulating files via engine functions.
            auth = "service_account"
          }
        }
      }
    }
    
    Local {
      # The actor that runs the backend. In this case, it's the Shared File System (SFS) ConfigBackend.
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"

      config {
        # Root directory where Cromwell writes job results.  This directory must be
        # visible and writeable by the Cromwell process as well as the jobs that Cromwell
        # launches.
        root = "/Users/vlad/CPG/cpg_qc/test/cromwell-executions"

        # If true submits scripts to the bash background using "&". Only usefull for dispatchers that do NOT submit
        # the job and then immediately return a scheduled job id.
        run-in-background = true

        # File system configuration.
        filesystems {

          # For SFS backends, the "local" configuration specifies how files are handled.
          local {

            # Try to hard link (ln), then soft-link (ln -s), and if both fail, then copy the files.
            localization: [
              "hard-link", "soft-link", "copy"
            ]
            # An experimental localization strategy called "cached-copy" is also available for SFS backends.
            # This will copy a file to a cache and then hard-link from the cache. It will copy the file to the cache again
            # when the maximum number of hardlinks for a file is reached. The maximum number of hardlinks can be set with:
            # max-hardlinks: 950

            # Call caching strategies
            caching {
              # When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:
              duplication-strategy: [
                "hard-link", "soft-link", "copy"
              ]

              # Possible values: file, path, path+modtime
              # "file" will compute an md5 hash of the file content.
              # "path" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to "soft-link",
              # in order to allow for the original file path to be hashed.
              # "path+modtime" will compute an md5 hash of the file path and the last modified time. The same conditions as for "path" apply here.
              # Default: file
              hashing-strategy: "file"

              # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.
              # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.
              check-sibling-md5: false
            }
          }
        }

        # The defaults for runtime attributes if not provided.
        default-runtime-attributes {
          failOnStderr: false
          continueOnReturnCode: 0
        }
      }
    }
  }
}
system {
  input-read-limits {
      lines = 1280000
      bool = 7
      int = 19
      float = 50
      string = 1280000
      json = 1280000
      tsv = 1280000
      map = 1280000
      object = 1280000
    }
}
call-caching {
  enabled = true
  invalidate-bad-cache-results = false
}
workflow-options {
  workflow-log-dir = "/Users/vlad/CPG/cpg_qc/test/cromwell-workflow-logs"
}